{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSS07Onq5mUm"
      },
      "source": [
        "## 1. Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itdD8-PC6VJi"
      },
      "source": [
        "#### Imports and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id0wtGhA6m8x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn, optim\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55pMDF187LO7"
      },
      "source": [
        "#### Bring in the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B4F-A-f7OCc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read in AMZN historical stock data as `data`\n",
        "filepath = \"AMZN.csv\"\n",
        "dataset = pd.read_csv(filepath)\n",
        "# print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOsdynwu7ilM"
      },
      "source": [
        "#### Clean up the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3H0bpDB7k-Q",
        "outputId": "4f331cb3-53d5-4bbe-9492-7a2a216fe7d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "# Reorder the columns\n",
        "dataset = dataset[['Open', 'High', 'Low', 'Volume', 'Close']]\n",
        "# Scale down Volume to tens of millions\n",
        "dataset['Volume'] = dataset['Volume'] / 10000000\n",
        "\n",
        "# dataset = dataset.to_numpy()\n",
        "# np.set_printoptions(suppress=True)\n",
        "# print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMVcQHYk6z4t"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXvp3tPRAgs6"
      },
      "source": [
        "### Split `Data` into Training, Test, Validation and Create Sequences\n",
        "Each sequence in for x is connected to a resulting y.\n",
        "<br>\n",
        "The value for sequence is currently set to 20, and should be adjusted to test the effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0HKioWOAgE5"
      },
      "outputs": [],
      "source": [
        "# # function to create train, validation, test data given stock data and sequence length\n",
        "# def load_data(stock, seq_len):\n",
        "#     data_raw = stock.values # convert to numpy array\n",
        "#     data = []\n",
        "    \n",
        "#     # create all possible sequences of length seq_len\n",
        "#     for index in range(len(data_raw) - seq_len): \n",
        "#         data.append(data_raw[index: index + seq_len])\n",
        "    \n",
        "#     data = np.array(data)\n",
        "#     valid_set_size = int(np.round(valid_set_size_percentage/100*data.shape[0])) \n",
        "#     test_set_size = int(np.round(test_set_size_percentage/100*data.shape[0]))\n",
        "#     train_set_size = data.shape[0] - (valid_set_size + test_set_size)\n",
        "    \n",
        "#     x_train = data[:train_set_size,:-1,:]\n",
        "#     y_train = data[:train_set_size,-1,4:] # last index (4:) makes it so we only take the 'Close' column\n",
        "    \n",
        "#     x_valid = data[train_set_size:train_set_size+valid_set_size,:-1,:]\n",
        "#     y_valid = data[train_set_size:train_set_size+valid_set_size,-1,4:]\n",
        "    \n",
        "#     x_test = data[train_set_size+valid_set_size:,:-1,:]\n",
        "#     y_test = data[train_set_size+valid_set_size:,-1,4:]\n",
        "    \n",
        "#     return [x_train, y_train, x_valid, y_valid, x_test, y_test]\n",
        "\n",
        "# # split data in 80%/10%/10% train/validation/test sets\n",
        "# valid_set_size_percentage = 10 \n",
        "# test_set_size_percentage = 10\n",
        "\n",
        "# # create train, test data\n",
        "# seq_length = 20 # choose sequence length\n",
        "# x_train, y_train, x_valid, y_valid, x_test, y_test = load_data(dataset, seq_length)\n",
        "\n",
        "# # y_train = np.squeeze(y_train)\n",
        "# # y_valid = np.squeeze(y_valid)\n",
        "# # y_test = np.squeeze(y_test)\n",
        "\n",
        "# # convert sequence to dataframe\n",
        "# def convert_sequence_to_dataframe(array):\n",
        "#     m,n,r = array.shape\n",
        "#     out_arr = np.column_stack((np.repeat(np.arange(m),n),array.reshape(m*n,-1)))\n",
        "#     out_df = pd.DataFrame(out_arr, columns=['Sequence', 'Open', 'High', 'Low', 'Volume', 'Close'])\n",
        "#     return out_df\n",
        "\n",
        "# # print(x_train)  \n",
        "# # x_train = convert_sequence_to_dataframe(x_train)\n",
        "# # y_train = pd.DataFrame(y_train, columns=['Close'])\n",
        "# # x_valid = convert_sequence_to_dataframe(x_valid)\n",
        "# # y_valid = pd.DataFrame(y_valid, columns=['Open', 'High', 'Low', 'Volume', 'Close'])\n",
        "# # x_test = convert_sequence_to_dataframe(x_test)\n",
        "# # y_test = pd.DataFrame(y_test, columns=['Open', 'High', 'Low', 'Volume', 'Close'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO3cKK1qAwE2"
      },
      "source": [
        "#### Printing Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW19_Ho-A0Fw"
      },
      "outputs": [],
      "source": [
        "def print_datasets():\n",
        "    print(x_train)\n",
        "    print(y_train)\n",
        "    print(x_valid)\n",
        "    print(y_valid)\n",
        "    print(x_test)\n",
        "    print(y_test)\n",
        "\n",
        "def print_shapes():\n",
        "    print('x_train.shape = ', x_train.shape)\n",
        "    print('y_train.shape = ', y_train.shape)\n",
        "    print('x_valid.shape = ', x_valid.shape)\n",
        "    print('y_valid.shape = ', y_valid.shape)\n",
        "    print('x_test.shape = ', x_test.shape)\n",
        "    print('y_test.shape = ', y_test.shape)\n",
        "\n",
        "# print_shapes()\n",
        "# print_datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfa9KNEeGQt-"
      },
      "source": [
        "### Split `Data` into Training, Test, Validation and Create Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVwTYSmvG0Zw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def feature_label_split(df, target_col):\n",
        "    y = df[[target_col]]\n",
        "    x = df.drop(columns=[target_col])\n",
        "    return x, y\n",
        "\n",
        "def train_val_test_split(df, target_col, test_ratio):\n",
        "    val_ratio = test_ratio / (1 - test_ratio)\n",
        "    x, y = feature_label_split(df, target_col)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_ratio, shuffle=False)\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=val_ratio, shuffle=False)\n",
        "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
        "\n",
        "x_train, x_val, x_test, y_train, y_val, y_test = train_val_test_split(dataset, 'Close', 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsAgpYgbHNP8"
      },
      "source": [
        "#### Printing Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVzJwpJSHPD_",
        "outputId": "d9d56894-8622-4fc1-a8db-d310932a8c69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train.shape =  (3690, 4)\n",
            "y_train.shape =  (3690, 1)\n",
            "x_val.shape =  (1230, 4)\n",
            "y_val.shape =  (1230, 1)\n",
            "x_test.shape =  (1230, 4)\n",
            "y_test.shape =  (1230, 1)\n"
          ]
        }
      ],
      "source": [
        "def print_datasets():\n",
        "    print(x_train)\n",
        "    print(y_train)\n",
        "    print(x_val)\n",
        "    print(y_val)\n",
        "    print(x_test)\n",
        "    print(y_test)\n",
        "\n",
        "def print_shapes():\n",
        "    print('x_train.shape = ', x_train.shape)\n",
        "    print('y_train.shape = ', y_train.shape)\n",
        "    print('x_val.shape = ', x_val.shape)\n",
        "    print('y_val.shape = ', y_val.shape)\n",
        "    print('x_test.shape = ', x_test.shape)\n",
        "    print('y_test.shape = ', y_test.shape)\n",
        "\n",
        "print_shapes()\n",
        "# print_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBK3HFCbF1El"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size = 500\n",
        "\n",
        "train_features = torch.Tensor(x_train.to_numpy())\n",
        "train_targets = torch.Tensor(y_train.to_numpy())\n",
        "val_features = torch.Tensor(x_val.to_numpy())\n",
        "val_targets = torch.Tensor(y_val.to_numpy())\n",
        "test_features = torch.Tensor(x_test.to_numpy())\n",
        "test_targets = torch.Tensor(y_test.to_numpy())\n",
        "\n",
        "train = TensorDataset(train_features, train_targets)\n",
        "val = TensorDataset(val_features, val_targets)\n",
        "test = TensorDataset(test_features, test_targets)\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "test_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz_dMzzaIaIZ"
      },
      "source": [
        "## 2. Define the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6w9b9yVIlnn"
      },
      "source": [
        "#### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNZjjiUlIj6G"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        super(LSTMModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device).requires_grad_()\n",
        "\n",
        "        # Initializing cell state for first input with zeros\n",
        "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device).requires_grad_()\n",
        "\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        # Forward propagation by passing in the input, hidden state, and cell state into the model\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz0jOPaziWZD"
      },
      "source": [
        "#### GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgXqL5m9iXrC"
      },
      "outputs": [],
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        super(GRUModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.layer_dim = layer_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # GRU layers\n",
        "        self.gru = nn.GRU(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device).requires_grad_()\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, _ = self.gru(x, h0.detach())\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwEnhdOTIsuF"
      },
      "source": [
        "#### Switch between models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ttry2DGaIv77"
      },
      "outputs": [],
      "source": [
        "def get_model(model, model_params):\n",
        "    models = {\n",
        "        # \"rnn\": RNNModel,\n",
        "        \"lstm\": LSTMModel,\n",
        "        \"gru\": GRUModel,\n",
        "    }\n",
        "    return models.get(model.lower())(**model_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFjv62UqIy6B"
      },
      "source": [
        "## 3. Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjJYvLErJL-d"
      },
      "source": [
        "##### Optimization Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rojFrTIKI1JT"
      },
      "outputs": [],
      "source": [
        "class Optimization:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "    \n",
        "    def train_step(self, x, y):\n",
        "        # Sets model to train mode\n",
        "        self.model.train()\n",
        "\n",
        "        # Makes predictions\n",
        "        yhat = self.model(x)\n",
        "\n",
        "        # Computes loss\n",
        "        loss = self.loss_fn(y, yhat)\n",
        "\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Updates parameters and zeroes gradients\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "    \n",
        "    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):\n",
        "        model_path = f'models/{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
        "\n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "            batch_losses = []\n",
        "            for x_batch, y_batch in train_loader:\n",
        "                x_batch = x_batch.view([batch_size, -1, n_features]).to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "                loss = self.train_step(x_batch, y_batch)\n",
        "                batch_losses.append(loss)\n",
        "            training_loss = np.mean(batch_losses)\n",
        "            self.train_losses.append(training_loss)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                batch_val_losses = []\n",
        "                for x_val, y_val in val_loader:\n",
        "                    x_val = x_val.view([batch_size, -1, n_features]).to(device)\n",
        "                    y_val = y_val.to(device)\n",
        "                    self.model.eval()\n",
        "                    yhat = self.model(x_val)\n",
        "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
        "                    batch_val_losses.append(val_loss)\n",
        "                validation_loss = np.mean(batch_val_losses)\n",
        "                self.val_losses.append(validation_loss)\n",
        "\n",
        "            if (epoch <= 10) | (epoch % 50 == 0):\n",
        "                print(\n",
        "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
        "                )\n",
        "\n",
        "        torch.save(self.model.state_dict(), model_path)\n",
        "\n",
        "    def evaluate(self, test_loader, batch_size=1, n_features=1):\n",
        "        with torch.no_grad():\n",
        "            predictions = []\n",
        "            values = []\n",
        "            for x_test, y_test in test_loader:\n",
        "                x_test = x_test.view([batch_size, -1, n_features]).to(device)\n",
        "                y_test = y_test.to(device)\n",
        "                self.model.eval()\n",
        "                yhat = self.model(x_test)\n",
        "                predictions.append(yhat.to(device).detach().cpu().clone().numpy())\n",
        "                values.append(y_test.to(device).detach().cpu().clone().numpy())\n",
        "\n",
        "        return predictions, values\n",
        "    \n",
        "    def plot_losses(self):\n",
        "        plt.plot(self.train_losses, label=\"Training loss\")\n",
        "        plt.plot(self.val_losses, label=\"Validation loss\")\n",
        "        plt.legend()\n",
        "        plt.title(\"Losses\")\n",
        "        plt.show()\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HUFKFmTKCIa"
      },
      "source": [
        "#### Start actually training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "qj1yCbNFKK58",
        "outputId": "a12accc1-7896-4b55-8151-7c8a74d3243a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/1000] Training loss: 4395.1999\t Validation loss: 123865.4805\n",
            "[2/1000] Training loss: 4365.0202\t Validation loss: 123652.8125\n",
            "[3/1000] Training loss: 4321.5737\t Validation loss: 123298.7070\n",
            "[4/1000] Training loss: 4260.1907\t Validation loss: 122832.5977\n",
            "[5/1000] Training loss: 4175.8956\t Validation loss: 122235.7930\n",
            "[6/1000] Training loss: 4071.4507\t Validation loss: 121463.3281\n",
            "[7/1000] Training loss: 3961.1837\t Validation loss: 120728.3984\n",
            "[8/1000] Training loss: 3855.0534\t Validation loss: 120045.2930\n",
            "[9/1000] Training loss: 3768.4590\t Validation loss: 119495.6875\n",
            "[10/1000] Training loss: 3694.9692\t Validation loss: 119012.0312\n",
            "[50/1000] Training loss: 2494.6695\t Validation loss: 109294.4629\n",
            "[100/1000] Training loss: 1753.8929\t Validation loss: 101148.2578\n",
            "[150/1000] Training loss: 1321.0585\t Validation loss: 94937.4746\n",
            "[200/1000] Training loss: 1039.4315\t Validation loss: 89863.4238\n",
            "[250/1000] Training loss: 833.5779\t Validation loss: 85468.9043\n",
            "[300/1000] Training loss: 677.4973\t Validation loss: 81638.4395\n",
            "[350/1000] Training loss: 566.4647\t Validation loss: 78227.7402\n",
            "[400/1000] Training loss: 485.5032\t Validation loss: 75157.3125\n",
            "[450/1000] Training loss: 429.3197\t Validation loss: 72302.5723\n",
            "[500/1000] Training loss: 465.5603\t Validation loss: 69923.6094\n",
            "[550/1000] Training loss: 309.8285\t Validation loss: 67382.6982\n",
            "[600/1000] Training loss: 263.4354\t Validation loss: 64964.2314\n",
            "[650/1000] Training loss: 238.5713\t Validation loss: 62684.9756\n",
            "[700/1000] Training loss: 193.3803\t Validation loss: 60537.6436\n",
            "[750/1000] Training loss: 203.5613\t Validation loss: 58529.1641\n",
            "[800/1000] Training loss: 202.6991\t Validation loss: 56619.5205\n",
            "[850/1000] Training loss: 151.5888\t Validation loss: 54814.6973\n",
            "[900/1000] Training loss: 108.8337\t Validation loss: 53166.8262\n",
            "[950/1000] Training loss: 180.5257\t Validation loss: 51584.2676\n",
            "[1000/1000] Training loss: 92.4384\t Validation loss: 50365.2764\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "input_dim = len(x_train.columns)\n",
        "output_dim = 1\n",
        "hidden_dim = 64\n",
        "layer_dim = 3\n",
        "# batch_size = 4032\n",
        "dropout = 0.2\n",
        "n_epochs = 1000\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-6\n",
        "\n",
        "model_params = {'input_dim': input_dim,\n",
        "                'hidden_dim' : hidden_dim,\n",
        "                'layer_dim' : layer_dim,\n",
        "                'output_dim' : output_dim,\n",
        "                'dropout_prob' : dropout}\n",
        "\n",
        "model = get_model('gru', model_params)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)\n",
        "opt.plot_losses()\n",
        "\n",
        "predictions, values = opt.evaluate(test_loader_one, batch_size=1, n_features=input_dim)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "itdD8-PC6VJi",
        "55pMDF187LO7",
        "cOsdynwu7ilM",
        "rXvp3tPRAgs6",
        "aO3cKK1qAwE2",
        "a6w9b9yVIlnn",
        "sz0jOPaziWZD",
        "TjJYvLErJL-d"
      ],
      "name": "Stock Prediction (LSTM, GRU, RNN).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
