{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.19.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: yahoo_fin in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.41.1)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: requests in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from yahoo_fin) (2.26.0)\n",
      "Requirement already satisfied: requests-html in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from yahoo_fin) (0.10.0)\n",
      "Requirement already satisfied: feedparser in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from yahoo_fin) (6.0.8)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->yahoo_fin) (2.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->yahoo_fin) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->yahoo_fin) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->yahoo_fin) (2021.5.30)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from feedparser->yahoo_fin) (1.0.0)\n",
      "Requirement already satisfied: pyquery in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-html->yahoo_fin) (1.4.3)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-html->yahoo_fin) (0.1.11)\n",
      "Requirement already satisfied: parse in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-html->yahoo_fin) (1.19.0)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-html->yahoo_fin) (0.2.6)\n",
      "Requirement already satisfied: w3lib in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-html->yahoo_fin) (1.22.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-html->yahoo_fin) (0.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.8.1)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.62.3)\n",
      "Requirement already satisfied: websockets<10.0,>=9.1 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (9.1)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (8.2.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bs4->requests-html->yahoo_fin) (4.10.0)\n",
      "Requirement already satisfied: cssselect>0.7.9 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyquery->requests-html->yahoo_fin) (1.1.0)\n",
      "Requirement already satisfied: lxml>=2.1 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyquery->requests-html->yahoo_fin) (4.6.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests-html->yahoo_fin) (0.4.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\le2ma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4->bs4->requests-html->yahoo_fin) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pandas numpy matplotlib yahoo_fin sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, GRU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "# Amazon stock market\n",
    "ticker = \"AMZN\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'df':                    open         high          low        close     adjclose  \\\n",
      "1997-05-15     2.437500     2.500000     1.927083     1.958333     1.958333   \n",
      "1997-05-16     1.968750     1.979167     1.708333     1.729167     1.729167   \n",
      "1997-05-19     1.760417     1.770833     1.625000     1.708333     1.708333   \n",
      "1997-05-20     1.729167     1.750000     1.635417     1.635417     1.635417   \n",
      "1997-05-21     1.635417     1.645833     1.375000     1.427083     1.427083   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2021-10-27  3388.000000  3437.000000  3371.449951  3392.489990  3392.489990   \n",
      "2021-10-28  3402.100098  3479.000000  3386.000000  3446.570068  3446.570068   \n",
      "2021-10-29  3300.020020  3374.820068  3273.320068  3372.429932  3372.429932   \n",
      "2021-11-01  3361.800049  3375.860107  3292.020020  3318.110107  3318.110107   \n",
      "2021-11-02  3315.010010  3331.120117  3283.550049  3312.750000  3312.750000   \n",
      "\n",
      "              volume ticker  \n",
      "1997-05-15  72156000   AMZN  \n",
      "1997-05-16  14700000   AMZN  \n",
      "1997-05-19   6106800   AMZN  \n",
      "1997-05-20   5467200   AMZN  \n",
      "1997-05-21  18853200   AMZN  \n",
      "...              ...    ...  \n",
      "2021-10-27   2702200   AMZN  \n",
      "2021-10-28   5708700   AMZN  \n",
      "2021-10-29   6469500   AMZN  \n",
      "2021-11-01   3608900   AMZN  \n",
      "2021-11-02   2624900   AMZN  \n",
      "\n",
      "[6159 rows x 7 columns], 'column_scaler': {'adjclose': MinMaxScaler(), 'volume': MinMaxScaler(), 'open': MinMaxScaler(), 'high': MinMaxScaler(), 'low': MinMaxScaler()}, 'last_sequence': array([[0.9020996 , 0.03534312, 0.8922458 , 0.89869636, 0.89256597],\n",
      "       [0.89901114, 0.01633925, 0.9025676 , 0.89813423, 0.9049568 ],\n",
      "       [0.9047135 , 0.0187429 , 0.89638734, 0.89816606, 0.9037012 ],\n",
      "       [0.8963891 , 0.02068624, 0.9014053 , 0.8944542 , 0.90048647],\n",
      "       [0.8955661 , 0.01599545, 0.89301807, 0.88911957, 0.90034574],\n",
      "       [0.8898851 , 0.01854163, 0.89339215, 0.8899468 , 0.8966872 ],\n",
      "       [0.8822257 , 0.02368984, 0.88976896, 0.8845645 , 0.8866182 ],\n",
      "       [0.8852793 , 0.01759307, 0.87869376, 0.878416  , 0.8844209 ],\n",
      "       [0.88272434, 0.01507675, 0.8828807 , 0.87617826, 0.88802797],\n",
      "       [0.88407016, 0.02727702, 0.87682337, 0.8745689 , 0.86857986],\n",
      "       [0.8687807 , 0.02793378, 0.8753538 , 0.86939603, 0.8725171 ],\n",
      "       [0.8578585 , 0.02231371, 0.86586577, 0.8623991 , 0.8655681 ],\n",
      "       [0.8542472 , 0.03173764, 0.85304844, 0.85680467, 0.8608218 ],\n",
      "       [0.85751796, 0.02748406, 0.85568035, 0.8501259 , 0.8590087 ],\n",
      "       [0.87519085, 0.02678011, 0.8578259 , 0.86950475, 0.86827683],\n",
      "       [0.88589054, 0.01988213, 0.8760218 , 0.8786758 , 0.8857496 ],\n",
      "       [0.88412106, 0.01148957, 0.8840029 , 0.8801367 , 0.8888804 ],\n",
      "       [0.88863045, 0.01551973, 0.8810985 , 0.88305324, 0.89154583],\n",
      "       [0.8976465 , 0.01833651, 0.89024454, 0.88844085, 0.89634895],\n",
      "       [0.91693336, 0.02604919, 0.89671063, 0.91301376, 0.9075708 ],\n",
      "       [0.930129  , 0.03726045, 0.9147116 , 0.9203263 , 0.918495  ],\n",
      "       [0.93233   , 0.03026425, 0.93384266, 0.934755  , 0.94004834],\n",
      "       [0.9280727 , 0.02346353, 0.9334045 , 0.93076736, 0.9345714 ],\n",
      "       [0.9320754 , 0.02011229, 0.92197925, 0.92300147, 0.929549  ],\n",
      "       [0.94045067, 0.02167427, 0.9289263 , 0.93504405, 0.94050837],\n",
      "       [0.9447965 , 0.02471254, 0.93791735, 0.93969446, 0.94557667],\n",
      "       [0.9337134 , 0.02149419, 0.94175696, 0.9408505 , 0.9414365 ],\n",
      "       [0.9296893 , 0.01835577, 0.93529356, 0.9298367 , 0.9367118 ],\n",
      "       [0.9264775 , 0.02004777, 0.93020886, 0.9270554 , 0.92997116],\n",
      "       [0.92455524, 0.01396063, 0.9282717 , 0.92409915, 0.92989266],\n",
      "       [0.93146944, 0.02378903, 0.91944623, 0.9237306 , 0.92023224],\n",
      "       [0.93480724, 0.02018836, 0.9241061 , 0.92562103, 0.9321738 ],\n",
      "       [0.9279118 , 0.03976618, 0.93170774, 0.92690957, 0.93379474],\n",
      "       [0.8992819 , 0.04027176, 0.90701634, 0.9061202 , 0.8939839 ],\n",
      "       [0.89603794, 0.02208837, 0.9014053 , 0.8957003 , 0.90139294],\n",
      "       [0.905802  , 0.01853007, 0.8949926 , 0.89816606, 0.9037364 ],\n",
      "       [0.91544   , 0.01822191, 0.9027546 , 0.90876096, 0.91428983],\n",
      "       [0.9179923 , 0.01568729, 0.9086222 , 0.90884054, 0.9179023 ],\n",
      "       [0.9127055 , 0.03030855, 0.9004701 , 0.9052108 , 0.9033467 ],\n",
      "       [0.8886197 , 0.03797693, 0.8967855 , 0.8929137 , 0.88994926],\n",
      "       [0.88464123, 0.01998324, 0.8872734 , 0.8881704 , 0.8920519 ],\n",
      "       [0.88033026, 0.02268061, 0.8856408 , 0.88195294, 0.8855899 ],\n",
      "       [0.879853  , 0.02261513, 0.87842923, 0.87700015, 0.88070554],\n",
      "       [0.85479146, 0.03886578, 0.8758588 , 0.86926347, 0.85914135],\n",
      "       [0.8631614 , 0.0267907 , 0.8558486 , 0.8641569 , 0.86623377],\n",
      "       [0.874156  , 0.01970108, 0.8582614 , 0.8651141 , 0.86519474],\n",
      "       [0.8849924 , 0.01850793, 0.87910527, 0.8813962 , 0.88804424],\n",
      "       [0.88129   , 0.01452495, 0.885908  , 0.88025075, 0.8894351 ],\n",
      "       [0.8699442 , 0.01489763, 0.8746858 , 0.87260425, 0.87587804],\n",
      "       [0.87022036, 0.01283103, 0.8698763 , 0.8659599 , 0.8753855 ],\n",
      "       [0.8801265 , 0.01861386, 0.87327236, 0.871488  , 0.88209915],\n",
      "       [0.88430345, 0.01562277, 0.8820203 , 0.8779096 , 0.89013326],\n",
      "       [0.91356874, 0.04514455, 0.88441706, 0.9038453 , 0.8937106 ],\n",
      "       [0.92368126, 0.02587489, 0.904975  , 0.91411936, 0.9156564 ],\n",
      "       [0.92298687, 0.01828643, 0.91724724, 0.91558295, 0.92564154],\n",
      "       [0.915188  , 0.01591456, 0.92215556, 0.91774917, 0.9197885 ],\n",
      "       [0.9205365 , 0.01342617, 0.91189265, 0.9117623 , 0.9205001 ],\n",
      "       [0.8938717 , 0.02553784, 0.9136962 , 0.9089943 , 0.901098  ],\n",
      "       [0.8898021 , 0.01674467, 0.8907175 , 0.88724244, 0.8920058 ],\n",
      "       [0.90473497, 0.02129292, 0.8945945 , 0.90535665, 0.9045292 ],\n",
      "       [0.90913707, 0.02133048, 0.9048788 , 0.91089267, 0.9119626 ],\n",
      "       [0.9236357 , 0.05028312, 0.9086463 , 0.9220284 , 0.9158999 ],\n",
      "       [0.90375906, 0.05760964, 0.881371  , 0.89440644, 0.8854086 ],\n",
      "       [0.88919616, 0.03006202, 0.89787835, 0.8946822 , 0.89046884],\n",
      "       [0.88775915, 0.02058608, 0.8853763 , 0.88281995, 0.88817686]],\n",
      "      dtype=float32), 'X_train': array([[[0.15358499, 0.02937636, 0.15369922, 0.15374567, 0.1541959 ],\n",
      "        [0.14960913, 0.05239595, 0.15179414, 0.1511155 , 0.14983112],\n",
      "        [0.14763595, 0.06557751, 0.14950427, 0.14871071, 0.14741735],\n",
      "        ...,\n",
      "        [0.18642132, 0.02029911, 0.18779589, 0.18680297, 0.18809679],\n",
      "        [0.18841864, 0.0245238 , 0.1861286 , 0.18720068, 0.18852435],\n",
      "        [0.18953122, 0.02677626, 0.18879788, 0.18809153, 0.19055927]],\n",
      "\n",
      "       [[0.00019828, 0.0396487 , 0.00024493, 0.00023476, 0.00021704],\n",
      "        [0.00027927, 0.08462472, 0.00019483, 0.00027342, 0.00022268],\n",
      "        [0.00025134, 0.02442942, 0.00027833, 0.00027757, 0.00026778],\n",
      "        ...,\n",
      "        [0.00050826, 0.01580863, 0.00054274, 0.0005358 , 0.00053275],\n",
      "        [0.0006842 , 0.08129659, 0.00052743, 0.00069875, 0.00055811],\n",
      "        [0.00083221, 0.15842144, 0.00069304, 0.00085617, 0.00071315]],\n",
      "\n",
      "       [[0.0133201 , 0.05159955, 0.01301604, 0.01329983, 0.01320736],\n",
      "        [0.01341662, 0.01115445, 0.01342752, 0.01338998, 0.01344819],\n",
      "        [0.01350777, 0.06124786, 0.01399664, 0.01392026, 0.01359432],\n",
      "        ...,\n",
      "        [0.01700105, 0.1104919 , 0.01640406, 0.01705948, 0.01653034],\n",
      "        [0.01699033, 0.10865642, 0.01675676, 0.01706213, 0.01685506],\n",
      "        [0.0161646 , 0.14066178, 0.01704533, 0.01698259, 0.01583219]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00873299, 0.04209087, 0.00859665, 0.00874743, 0.00873162],\n",
      "        [0.00878393, 0.04629629, 0.00874895, 0.00870501, 0.00875056],\n",
      "        [0.00865256, 0.05390112, 0.00876498, 0.0087978 , 0.00872079],\n",
      "        ...,\n",
      "        [0.0091539 , 0.05226594, 0.00910431, 0.00904703, 0.00915105],\n",
      "        [0.00907615, 0.03260434, 0.0090482 , 0.00901522, 0.00916729],\n",
      "        [0.00912977, 0.0414081 , 0.00905087, 0.0090762 , 0.00916187]],\n",
      "\n",
      "       [[0.05571941, 0.03458138, 0.05630687, 0.05608502, 0.0558622 ],\n",
      "        [0.056706  , 0.04291905, 0.05559614, 0.05629978, 0.05568901],\n",
      "        [0.05544863, 0.03336126, 0.05531825, 0.05562103, 0.05574043],\n",
      "        ...,\n",
      "        [0.06235745, 0.01306312, 0.06256457, 0.06211955, 0.06291406],\n",
      "        [0.06304646, 0.01512972, 0.06218248, 0.06271876, 0.06276252],\n",
      "        [0.06246201, 0.01008359, 0.06249242, 0.06230779, 0.06285453]],\n",
      "\n",
      "       [[0.0140949 , 0.03366461, 0.01374281, 0.01394942, 0.01394069],\n",
      "        [0.0142772 , 0.10627299, 0.01415963, 0.01413237, 0.01400022],\n",
      "        [0.01408417, 0.05537933, 0.01418635, 0.01413237, 0.0142167 ],\n",
      "        ...,\n",
      "        [0.01205201, 0.05798136, 0.01194459, 0.01200596, 0.01195989],\n",
      "        [0.01192064, 0.05449529, 0.01211559, 0.01202452, 0.0120113 ],\n",
      "        [0.01184826, 0.0429672 , 0.01187512, 0.0118787 , 0.01195989]]],\n",
      "      dtype=float32), 'X_test': array([[[5.5925839e-02, 3.6062479e-02, 5.5451851e-02, 5.5477861e-02,\n",
      "         5.5659249e-02],\n",
      "        [5.7582669e-02, 5.5170354e-02, 5.4337651e-02, 5.7044823e-02,\n",
      "         5.4974627e-02],\n",
      "        [5.8579981e-02, 4.6306890e-02, 5.8086388e-02, 5.7996664e-02,\n",
      "         5.7612989e-02],\n",
      "        ...,\n",
      "        [5.6252915e-02, 4.0382504e-02, 5.7057690e-02, 5.6806196e-02,\n",
      "         5.6633413e-02],\n",
      "        [5.6137633e-02, 4.3887831e-02, 5.6670256e-02, 5.6371372e-02,\n",
      "         5.5956911e-02],\n",
      "        [5.7907064e-02, 4.5028985e-02, 5.6408409e-02, 5.7384197e-02,\n",
      "         5.6554936e-02]],\n",
      "\n",
      "       [[5.7354789e-02, 3.1258065e-02, 5.7955462e-02, 5.7646681e-02,\n",
      "         5.7542633e-02],\n",
      "        [5.7877574e-02, 3.6176115e-02, 5.6993563e-02, 5.7296701e-02,\n",
      "         5.6790359e-02],\n",
      "        [5.7330661e-02, 2.5557097e-02, 5.7600092e-02, 5.7325866e-02,\n",
      "         5.7201672e-02],\n",
      "        ...,\n",
      "        [6.2920451e-02, 3.1289846e-02, 6.2949322e-02, 6.3445233e-02,\n",
      "         6.2984422e-02],\n",
      "        [6.2172465e-02, 2.8566476e-02, 6.2441658e-02, 6.2268026e-02,\n",
      "         6.2318739e-02],\n",
      "        [6.1848067e-02, 1.9805089e-02, 6.2185150e-02, 6.1758962e-02,\n",
      "         6.2072489e-02]],\n",
      "\n",
      "       [[1.3404775e-03, 5.2002080e-02, 1.3081391e-03, 1.3174005e-03,\n",
      "         1.3079048e-03],\n",
      "        [1.4912812e-03, 2.1733403e-01, 1.3359719e-03, 1.5107295e-03,\n",
      "         1.3755551e-03],\n",
      "        [1.4825541e-03, 2.3365112e-01, 1.5280178e-03, 1.5659666e-03,\n",
      "         1.5136745e-03],\n",
      "        ...,\n",
      "        [1.7007309e-03, 1.2958919e-01, 1.6393489e-03, 1.6930114e-03,\n",
      "         1.6687064e-03],\n",
      "        [1.6714080e-03, 7.8130238e-02, 1.6727482e-03, 1.7068208e-03,\n",
      "         1.6968938e-03],\n",
      "        [1.6281217e-03, 3.9879818e-02, 1.6699649e-03, 1.6598692e-03,\n",
      "         1.6630687e-03]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[5.0267907e-05, 4.7876582e-02, 8.0714883e-05, 6.9045978e-05,\n",
      "         5.9193975e-05],\n",
      "        [3.9097431e-05, 6.7487145e-03, 5.0098944e-05, 4.1427687e-05,\n",
      "         5.9193975e-05],\n",
      "        [5.5853401e-05, 1.1024441e-02, 4.7315585e-05, 5.2474901e-05,\n",
      "         6.4831409e-05],\n",
      "        ...,\n",
      "        [1.9269364e-04, 1.0689316e-02, 1.9482932e-04, 1.8780543e-04,\n",
      "         1.6912563e-04],\n",
      "        [1.7314518e-04, 1.2492055e-02, 1.7256296e-04, 1.6018689e-04,\n",
      "         1.7758193e-04],\n",
      "        [2.0665712e-04, 4.9690874e-03, 1.8369613e-04, 2.0161457e-04,\n",
      "         2.0013192e-04]],\n",
      "\n",
      "       [[2.0700771e-02, 6.1488606e-02, 2.0144787e-02, 2.0787308e-02,\n",
      "         2.0213220e-02],\n",
      "        [2.0518467e-02, 4.8742320e-02, 2.0652454e-02, 2.0553989e-02,\n",
      "         2.0353932e-02],\n",
      "        [1.9515790e-02, 7.9768300e-02, 1.9997830e-02, 1.9938869e-02,\n",
      "         1.9672018e-02],\n",
      "        ...,\n",
      "        [2.2641782e-02, 4.3955240e-02, 2.2549536e-02, 2.2550471e-02,\n",
      "         2.2700042e-02],\n",
      "        [2.3279851e-02, 5.3633403e-02, 2.2675116e-02, 2.3181498e-02,\n",
      "         2.2986881e-02],\n",
      "        [2.3488965e-02, 6.9734789e-02, 2.3276303e-02, 2.3215966e-02,\n",
      "         2.3295365e-02]],\n",
      "\n",
      "       [[2.6831913e-01, 2.3451975e-02, 2.6647130e-01, 2.6547447e-01,\n",
      "         2.6825696e-01],\n",
      "        [2.6806980e-01, 1.7008532e-02, 2.6741448e-01, 2.6659867e-01,\n",
      "         2.6948819e-01],\n",
      "        [2.6872396e-01, 2.3034032e-02, 2.6749730e-01, 2.6597825e-01,\n",
      "         2.6971006e-01],\n",
      "        ...,\n",
      "        [2.5324950e-01, 2.0314516e-02, 2.5253442e-01, 2.5229186e-01,\n",
      "         2.5461864e-01],\n",
      "        [2.5540498e-01, 2.2987809e-02, 2.5078696e-01, 2.5308728e-01,\n",
      "         2.5301671e-01],\n",
      "        [2.5903231e-01, 2.3279598e-02, 2.5571403e-01, 2.5664276e-01,\n",
      "         2.5858566e-01]]], dtype=float32), 'y_train': array([0.19198699, 0.00069817, 0.01853188, ..., 0.00909224, 0.06587754,\n",
      "       0.01119947]), 'y_test': array([0.05223685, 0.0647998 , 0.00169235, ..., 0.00051106, 0.02202784,\n",
      "       0.25824412]), 'test_df':                    open         high          low        close     adjclose  \\\n",
      "2011-11-11   212.520004   217.880005   210.309998   217.389999   217.389999   \n",
      "2012-08-01   234.139999   234.380005   230.699997   232.089996   232.089996   \n",
      "1998-05-15     7.656250     7.708333     7.458333     7.468750     7.468750   \n",
      "2016-05-04   662.590027   674.000000   662.140015   670.900024   670.900024   \n",
      "2009-03-27    71.610001    72.290001    70.099998    70.519997    70.519997   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2018-12-14  1638.000000  1642.569946  1585.000000  1591.910034  1591.910034   \n",
      "2014-06-25   324.329987   328.149994   321.739990   327.440002   327.440002   \n",
      "1997-08-19     2.093750     2.208333     2.052083     2.166667     2.166667   \n",
      "2009-07-21    88.519997    89.010002    87.400002    89.010002    89.010002   \n",
      "2017-08-30   958.440002   969.409973   956.909973   967.590027   967.590027   \n",
      "\n",
      "             volume ticker  \n",
      "2011-11-11  5163100   AMZN  \n",
      "2012-08-01  2543800   AMZN  \n",
      "1998-05-15  4628400   AMZN  \n",
      "2016-05-04  4635500   AMZN  \n",
      "2009-03-27  8568800   AMZN  \n",
      "...             ...    ...  \n",
      "2018-12-14  6367200   AMZN  \n",
      "2014-06-25  2327800   AMZN  \n",
      "1997-08-19  1003200   AMZN  \n",
      "2009-07-21  7728600   AMZN  \n",
      "2017-08-30  2904600   AMZN  \n",
      "\n",
      "[1219 rows x 7 columns]}\n"
     ]
    }
   ],
   "source": [
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE,\n",
    "                 shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
    "                 feature_columns=FEATURE_COLUMNS)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28936/2320991902.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# train the model and save the weights whenever we see\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# a new optimal model using ModelCheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m history = model.fit(data[\"X_train\"], data[\"y_train\"],\n\u001b[0m\u001b[0;32m     17\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1150\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCallbackList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m         callbacks = callbacks_module.CallbackList(\n\u001b[0m\u001b[0;32m   1153\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m             \u001b[0madd_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, callbacks, add_history, add_progbar, model, **params)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    283\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_history\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m   2217\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_write_train_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2218\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2219\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_keras_model_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2220\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_write_train_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2221\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings_freq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_write_keras_model_summary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2256\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_write_keras_model_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2257\u001b[0m     \u001b[1;34m\"\"\"Writes Keras graph network summary to TensorBoard.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2258\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2259\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_if\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2260\u001b[0m         summary_writable = (\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_train_writer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2225\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'train'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2227\u001b[1;33m       self._writers['train'] = tf.summary.create_file_writer(\n\u001b[0m\u001b[0;32m   2228\u001b[0m           self._train_dir)\n\u001b[0;32m   2229\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36mcreate_file_writer_v2\u001b[1;34m(logdir, max_queue, flush_millis, filename_suffix, name, experimental_trackable)\u001b[0m\n\u001b[0;32m    551\u001b[0m             create_fn=create_fn, init_op_fn=init_op_fn)\n\u001b[0;32m    552\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m         return _ResourceSummaryWriter(\n\u001b[0m\u001b[0;32m    554\u001b[0m             create_fn=create_fn, init_op_fn=init_op_fn)\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, create_fn, init_op_fn)\u001b[0m\n\u001b[0;32m    311\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_op_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_op_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_summary_ops.py\u001b[0m in \u001b[0;36mcreate_summary_file_writer\u001b[1;34m(writer, logdir, max_queue, flush_millis, filename_suffix, name)\u001b[0m\n\u001b[0;32m    138\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"CreateSummaryFileWriter\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         flush_millis, filename_suffix)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE,\n",
    "                 shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
    "                 feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                     dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\n",
    "    \"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see\n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir=\"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bfc3d9062e4aa719b2794ce0b670a49d0e14c19d264706ec73cfc63b237b7d4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
